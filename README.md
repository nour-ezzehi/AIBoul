# ğŸ¥– RAG â€“ Assistant Intelligent pour Fiches Techniques en Boulangerie

## ğŸ“Œ Contexte

Dans le cadre dâ€™un projet dâ€™assistance Ã  la formulation en boulangerie et pÃ¢tisserie, nous disposons dâ€™un ensemble de fiches techniques (enzymes, amÃ©liorants, agents oxydants, etc.).

Ces fiches ont dÃ©jÃ  Ã©tÃ© :

- Converties en texte  
- DÃ©coupÃ©es en fragments (chunks)  
- TransformÃ©es en embeddings  
- StockÃ©es dans une base PostgreSQL (pgvector)  

Lâ€™objectif est de dÃ©velopper un module de **recherche sÃ©mantique (RAG â€“ Retrieval Augmented Generation)** permettant dâ€™interroger cette base vectorielle Ã  partir dâ€™une question en langage naturel.

---

# ğŸ— Architecture du SystÃ¨me

## ğŸ” Pipeline RAG

```text
Question utilisateur
        â†“
Embedding (all-MiniLM-L6-v2)
        â†“
Recherche vectorielle (PostgreSQL + pgvector)
        â†“
Top 3 fragments les plus similaires
        â†“
(Optionnel) LLM â†’ GÃ©nÃ©ration dâ€™une rÃ©ponse synthÃ©tique
---

## ğŸ§  Composants

### 1ï¸âƒ£ GÃ©nÃ©ration dâ€™embedding

- ModÃ¨le : all-MiniLM-L6-v2  
- BibliothÃ¨que : sentence-transformers  
- Dimension : 384  

Lâ€™embedding de la question est gÃ©nÃ©rÃ© avec le mÃªme modÃ¨le que celui utilisÃ© pour indexer les documents, garantissant la compatibilitÃ© dans lâ€™espace vectoriel.

---

### 2ï¸âƒ£ Base de donnÃ©es vectorielle

Base : PostgreSQL  
Extension : pgvector  

Table : embeddings

| Colonne         | Type          |
|----------------|--------------|
| id             | Primary Key  |
| id_document    | int          |
| texte_fragment | text         |
| vecteur        | VECTOR(384)  |

Les embeddings des fragments sont dÃ©jÃ  stockÃ©s dans cette table.

---

### 3ï¸âƒ£ Recherche par similaritÃ©

La similaritÃ© entre la question et les fragments est calculÃ©e via la similaritÃ© cosinus :

cos(Î¸) = (A Â· B) / (||A|| ||B||)

Les fragments sont :

- ClassÃ©s par ordre dÃ©croissant de pertinence
- LimitÃ©s aux 3 plus proches

---

### 4ï¸âƒ£ (Optionnel) GÃ©nÃ©ration avec LLM

Les fragments rÃ©cupÃ©rÃ©s peuvent Ãªtre injectÃ©s dans un modÃ¨le de langage afin de :

- GÃ©nÃ©rer une rÃ©ponse synthÃ©tique
- Fournir une explication contextualisÃ©e
- AmÃ©liorer lâ€™expÃ©rience utilisateur

---

# âš™ï¸ FonctionnalitÃ©s du Prototype

âœ” Question libre en langage naturel  
âœ” GÃ©nÃ©ration dynamique dâ€™embedding  
âœ” Interrogation PostgreSQL avec recherche vectorielle  
âœ” Retour des 3 fragments les plus pertinents  
âœ” Affichage des scores de similaritÃ©  
âœ” Option dâ€™activation du LLM  

---

# ğŸ¯ Explication Technique (Pitch Court)

Le systÃ¨me implÃ©mente une architecture RAG industrielle.

Lorsquâ€™un utilisateur pose une question :

1. La question est encodÃ©e en un vecteur 384 dimensions via le modÃ¨le all-MiniLM-L6-v2.
2. Ce vecteur est comparÃ© aux embeddings des fragments stockÃ©s dans PostgreSQL via lâ€™extension pgvector.
3. La similaritÃ© cosinus est utilisÃ©e pour mesurer la proximitÃ© sÃ©mantique.
4. Les trois fragments les plus pertinents sont retournÃ©s.
5. Optionnellement, ces fragments sont transmis Ã  un LLM pour gÃ©nÃ©rer une rÃ©ponse synthÃ©tique contextualisÃ©e.

Cette approche permet une recherche basÃ©e sur la comprÃ©hension du sens, et non sur une simple correspondance lexicale.

---

# ğŸš€ Valeur AjoutÃ©e

- Recherche sÃ©mantique avancÃ©e  
- Exploitation dâ€™une base vectorielle industrielle  
- Architecture Ã©volutive  
- Compatible avec des bases documentaires volumineuses  
- Extensible vers index ANN (HNSW / IVFFlat)  

---

# ğŸ Conclusion

Ce prototype dÃ©montre la mise en Å“uvre complÃ¨te dâ€™un module de Retrieval dans une architecture RAG, permettant une recherche intelligente et contextualisÃ©e au sein de fiches techniques en boulangerie et pÃ¢tisserie.
